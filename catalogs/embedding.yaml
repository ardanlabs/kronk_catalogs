catalog: Embedding
models:
  - id: embeddinggemma-300m-qat-Q8_0
    testing_model: true
    category: Embedding
    owned_by: ggml-org
    model_family: embeddinggemma-300m-qat-q8_0-GGUF
    architecture: Dense
    gguf_arch: gemma-embedding
    web_page: https://huggingface.co/ggml-org/embeddinggemma-300m-qat-q8_0-GGUF
    files:
      models:
        - url: https://huggingface.co/ggml-org/embeddinggemma-300m-qat-q8_0-GGUF/resolve/main/embeddinggemma-300m-qat-Q8_0.gguf
          size: 329 MB
    capabilities:
      endpoint: embeddings
      embedding: true
    metadata:
      created: 2025-09-01T00:00:00Z
      collections: https://huggingface.co/ggml-org
      description:
        The embeddinggemma-300M-GGUF model is a quantized version of Google's
        EmbeddingGemma, a lightweight, open, and multilingual text embedding model designed
        for efficient performance on on-device hardware like laptops, phones, and desktops.
    config:
      context-window: 2048
      nbatch: 1024
      nubatch: 512
      cache-type-k: q8_0
      cache-type-v: q8_0
